{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docx\n",
    "from docx import Document\n",
    "import re\n",
    "import shutil\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import aspose.words as aw\n",
    "from xml.etree.ElementTree import ParseError\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEER RUTA DE ARCHIVO tipo A\n",
    "docx_path = 'AI-Redações/RedaçõesDownloaded/R1/Ana Luiza Ferreira Braulio A.docx'\n",
    "docx_path1 = 'AI-Redações/RedaçõesDownloaded/R1/Claudio Gabriel A11.docx'\n",
    "docx_path2 = 'AI-Redações/RedaçõesDownloaded/R1/Érico Breyer de Freitas A.docx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEER RUTA DE ARCHIVO tipo Z\n",
    "docx_pathZ = 'AI-Redações/RedaçõesDownloaded/R1/DIOGO DAVID SÁNCHEZ LIMA Z.docx'\n",
    "docx_path1Z = 'AI-Redações/RedaçõesDownloaded/R1/Davi Natael da Cunha  ZZ.docx'\n",
    "docx_path2Z = 'AI-Redações/RedaçõesDownloaded/R1/Carallow ZZ.docx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_xml_de_docx(docx_path, output_folder): #CREA CARPETA\n",
    "    # Asegurarse de que la carpeta de salida existe\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    with zipfile.ZipFile(docx_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_folder)\n",
    "        \n",
    "def extraer_texto_LIMPIO(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    texto_completo = []\n",
    "    for para in doc.paragraphs:\n",
    "        texto_completo.append(para.text)\n",
    "    return '\\n'.join(texto_completo)\n",
    "\n",
    "def todo(docx_path):\n",
    "    docToRead = aw.Document(docx_path)\n",
    "    TEXTO = []\n",
    "    for paragraph in docToRead.get_child_nodes(aw.NodeType.PARAGRAPH, True) :    \n",
    "        paragraph = paragraph.as_paragraph()\n",
    "        TEXTO.append(paragraph.to_string(aw.SaveFormat.TEXT))\n",
    "    return TEXTO\n",
    "\n",
    "#EXTRAE LIMPIO\n",
    "def extraer_texto_en_parrafosTOTAL_SINEXCLUIDAS(docx_path):\n",
    "    with zipfile.ZipFile(docx_path) as docx:\n",
    "        xml_content = docx.read('word/document.xml')\n",
    "    try:\n",
    "        tree = ET.ElementTree(ET.fromstring(xml_content))\n",
    "    except ParseError:\n",
    "        return \"Error al analizar el XML\"\n",
    "    parrafos = []\n",
    "    for elem in tree.iter():\n",
    "        if elem.tag.endswith('}p'):\n",
    "            parrafo = []\n",
    "            for subelem in elem.iter():\n",
    "                if subelem.tag.endswith('}t') and subelem.text:\n",
    "                    parrafo.append(subelem.text)\n",
    "            parrafos.append(''.join(parrafo))\n",
    "    return parrafos\n",
    "\n",
    "def extraer_comentarios(docx_path):\n",
    "    \n",
    "    with zipfile.ZipFile(docx_path) as docx:\n",
    "        if zipfile.ZipFile(docx_path) != {}:\n",
    "            comments_xml = docx.read('word/comments.xml')\n",
    "            tree = ET.fromstring(comments_xml)\n",
    "            comments = []\n",
    "            namespace = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "            for comment in tree.iter(namespace + 'comment'):\n",
    "                text = ''.join(t.text for t in comment.iter(namespace + 't') if t.text)\n",
    "                comments.append(text)\n",
    "        else:\n",
    "            comments = []\n",
    "  \n",
    "            \n",
    "    #tree = ET.fromstring(comments_xml)\n",
    "    #comments = []\n",
    "    #namespace = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "    #for comment in tree.iter(namespace + 'comment'):\n",
    "    #    text = ''.join(t.text for t in comment.iter(namespace + 't') if t.text)\n",
    "    #    comments.append(text)\n",
    "    return comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_comment_range_start(comentario):\n",
    "    # Recorrer hacia atrás desde el comentario hasta encontrar CommentRangeStart\n",
    "    nodo_actual = comentario.previous_sibling\n",
    "    while nodo_actual is not None:\n",
    "        if nodo_actual.node_type == aw.NodeType.COMMENT_RANGE_START:\n",
    "            return nodo_actual\n",
    "        nodo_actual = nodo_actual.previous_sibling\n",
    "    return None\n",
    "\n",
    "def encontrar_comment_range_end(comentario):\n",
    "    # Recorrer hacia adelante desde el comentario hasta encontrar CommentRangeEnd\n",
    "    nodo_actual = comentario.previous_sibling #next_sibling\n",
    "    while nodo_actual is not None:\n",
    "        if nodo_actual.node_type == aw.NodeType.COMMENT_RANGE_END:\n",
    "            return nodo_actual\n",
    "        nodo_actual = nodo_actual.next_sibling\n",
    "    return None\n",
    "\n",
    "def extraer_texto_entre_nodos(doc, nodo_inicio, nodo_fin):\n",
    "    # Extraer el texto entre dos nodos\n",
    "    texto = []\n",
    "    if nodo_inicio is not None:\n",
    "        nodo_actual = nodo_inicio.next_sibling\n",
    "        while nodo_actual is not None and nodo_actual != nodo_fin:\n",
    "            if nodo_actual.node_type == aw.NodeType.RUN:\n",
    "                texto.append(nodo_actual.get_text())\n",
    "            nodo_actual = nodo_actual.next_sibling\n",
    "    return ''.join(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_comentarios_y_texto_asociado(documento):\n",
    "    # Cargar el documento\n",
    "    doc = aw.Document(documento)\n",
    "\n",
    "    # Lista para almacenar pares de comentario y texto asociado\n",
    "    comentarios_y_texto = []\n",
    "\n",
    "    # Obtener todos los comentarios\n",
    "    comentarios = doc.get_child_nodes(aw.NodeType.COMMENT, True)\n",
    "\n",
    "    for comentario in comentarios:\n",
    "        comentario = comentario.as_comment()\n",
    "\n",
    "        # Encontrar el CommentRangeStart más cercano\n",
    "        comment_range_start = encontrar_comment_range_start(comentario)\n",
    "\n",
    "        # Encontrar el CommentRangeEnd más cercano\n",
    "        comment_range_end = encontrar_comment_range_end(comentario)\n",
    "\n",
    "        # Extraer el texto asociado con este comentario\n",
    "        texto_asociado = extraer_texto_entre_nodos(doc, comment_range_start, comment_range_end)\n",
    "\n",
    "        comentarios_y_texto.append((comentario.get_text().strip(), texto_asociado))\n",
    "\n",
    "    return comentarios_y_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAR VARIABLE JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAR VARIABLE JSON PARA DOCUMENTOS TIPO \"A\"\n",
    "\n",
    "def JSONTipoA(docx_path):\n",
    "    texto_LIMPIO = extraer_texto_LIMPIO(docx_path) #extraer_texto_en_parrafosTOTAL_SINEXCLUIDAS\n",
    "    texto_LIMPIO = texto_LIMPIO.splitlines()\n",
    "    texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"] \n",
    "    #NOME\n",
    "    nome = texto_LIMPIO[0].replace(\"Nome: \", \"\").replace(\"Nome:\", \"\").replace(\"Aluno: \", \"\").replace(\"Aluno:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CORREO\n",
    "    correo = texto_LIMPIO[0].replace(\"E-mail: \", \"\").replace(\"E-mail:\", \"\").replace(\"Email: \", \"\").replace(\"Email:\", \"\").replace(\"\\xa0\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CODIGO\n",
    "    codigo = texto_LIMPIO[0].replace(\"Código de identificação: \", \"\").replace(\"Código de identificação:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #NOTA\n",
    "    nota = texto_LIMPIO[-1].replace(\"NOTA: \", \"\").replace(\"nota: \", \"\")\n",
    "    del texto_LIMPIO[-1]\n",
    "    \n",
    "    print(\"nome\",nome)\n",
    "    print(\"texto_LIMPIO\", len(texto_LIMPIO))\n",
    "    indice = next((i for i in reversed(range(len(texto_LIMPIO))) if nome.split()[0] in texto_LIMPIO[i] or nome.split()[0] + \" \" + nome.split()[1] in texto_LIMPIO[i]), None)\n",
    "    print(\"indice\",indice)\n",
    "    \n",
    "    #if indice is not None:\n",
    "    cuerpo = texto_LIMPIO[:indice]\n",
    "    conclusion = texto_LIMPIO[indice:]        \n",
    "    comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_path)\n",
    "    comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "\n",
    "    datos = {\n",
    "        \"NOMBRE\": nome,\n",
    "        \"CORREO\": correo,\n",
    "        \"CODIGO\": codigo,\n",
    "        \"CUERPO\": cuerpo,\n",
    "        \"COMENTARIOS\": comentarios_texto,\n",
    "        \"CONCLUSION\": {\n",
    "            \"NOTA\": nota,\n",
    "            \"TEXT\": conclusion\n",
    "        }\n",
    "    }\n",
    "    # Convertir el diccionario a una cadena JSON\n",
    "    json_str = json.dumps(datos, ensure_ascii=False, indent=4)\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI-Redações/RedaçõesDownloaded/R1/Ana Luiza Ferreira Braulio A.docx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON = JSONTipoA(docx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"/home/andres/Documents/analisisTexto/AI-Redações/RedaçõesDownloaded/R1\"\n",
    "\n",
    "# Dividir la ruta por cada \"/\"\n",
    "partes = ruta.split(\"/\")\n",
    "\n",
    "# Seleccionar la última parte\n",
    "ultima_parte = partes[-1]\n",
    "\n",
    "print(ultima_parte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_carpeta1 = '/home/andres/Documents/analisisTexto/AI-Redações/RedaçõesDownloaded/'\n",
    "archivos_filtrados1 = []\n",
    "for archivo in os.listdir(ruta_carpeta1):\n",
    "    archivos_filtrados1.append(archivo)\n",
    "print(archivos_filtrados1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_filtradosA, archivos_filtradosZ, archivos_filtradosR = [],[],[]\n",
    "\n",
    "for i in archivos_filtrados1:\n",
    "    ruta_archivo = ruta_carpeta1 + str(i)\n",
    "    #print(ruta_archivo)\n",
    "    \n",
    "    #for j in ruta_archivo:\n",
    "            # Recorre todos los archivos en el directorio\n",
    "    for archivo in os.listdir(ruta_archivo):\n",
    "            #print(archivo)\n",
    "            if archivo.endswith('A.docx') or archivo.endswith('A1.docx') or archivo.endswith('A11.docx') or archivo.endswith('A2.docx') or archivo.endswith('A3.docx'):\n",
    "                dic = {\n",
    "                    \"id\":i,\n",
    "                    \"archivo\":archivo  \n",
    "                }\n",
    "                archivos_filtradosA.append(dic)\n",
    "            \n",
    "            elif archivo.endswith('Z.docx') or archivo.endswith('Z1.docx') or archivo.endswith('Z11.docx') or archivo.endswith('Z2.docx'):\n",
    "                dic1 = {\n",
    "                    \"id\":i,\n",
    "                    \"archivo\":archivo  \n",
    "                }\n",
    "                archivos_filtradosZ.append(dic1) \n",
    "            \n",
    "            elif archivo.endswith('R.docx') or archivo.endswith('R1.docx') or archivo.endswith('R2.docx') or archivo.endswith('R3.docx') or archivo.endswith('RR12.docx'):\n",
    "                dic2 = {\n",
    "                    \"id\":i,\n",
    "                    \"archivo\":archivo  \n",
    "                }\n",
    "                archivos_filtradosR.append(dic2) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(archivos_filtradosA), len(archivos_filtradosZ), len(archivos_filtradosR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'AI-Redações/RedaçõesDownloaded/'\n",
    "for i in archivos_filtradosA:\n",
    "    i[\"JSON\"] = JSONTipoA(r+str(i[\"id\"])+\"/\"+str(i[\"archivo\"]))\n",
    "    #JSON = JSONTipoA(r+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Tu diccionario\n",
    "#mi_diccionario = {'clave1': 'valor1', 'clave2': 'valor2'}\n",
    "\n",
    "# Escribir el diccionario a un archivo JSON\n",
    "with open('archivos_filtradosA.json', 'w') as archivo_json:\n",
    "    json.dump(archivos_filtradosA, archivo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(archivos_filtradosA[1]['JSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(archivos_filtrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {}\n",
    "Lid,Larchivo,Ltexto,Lcomentario,Lpalabras_corregidas = [],[],[],[],[]\n",
    "tabla = pd.DataFrame()\n",
    "for j in range(len(archivos_filtradosA)):\n",
    "    data = json.loads(archivos_filtradosA[j]['JSON'])\n",
    "    #data[\"COMENTARIOS\"]\n",
    "    for i in range(len(data[\"COMENTARIOS\"])):\n",
    "        print(data[\"COMENTARIOS\"][i][1])\n",
    "        #tabla[\"texto\"] = [data[\"COMENTARIOS\"][i][1]]\n",
    "        #texto = data[\"COMENTARIOS\"][i][1]\n",
    "        Lid.append(archivos_filtradosA[j][\"id\"])\n",
    "        Larchivo.append(archivos_filtradosA[j]['archivo'])\n",
    "        Ltexto.append(data[\"COMENTARIOS\"][i][1])\n",
    "        Lcomentario.append(data[\"COMENTARIOS\"][i][0])\n",
    "        Lpalabras_corregidas.append(data[\"PALABRAS_CORREGIDAS\"])\n",
    "        #comentario = data[\"COMENTARIOS\"][i][0]\n",
    "        print(data[\"COMENTARIOS\"][i][0])\n",
    "        #diccionario[\"texto\"] = texto\n",
    "        #diccionario[\"comentario\"] = comentario\n",
    "        #tabla[\"comentario\"] = [data[\"COMENTARIOS\"][i][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {\n",
    "    \"id\":Lid,\n",
    "    \"archivo\":Larchivo,\n",
    "    \"texto\": Ltexto,\n",
    "    \"comentario\":Lcomentario,\n",
    "    \"palabras_corregidas\":Lpalabras_corregidas\n",
    "}\n",
    "df = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"archivo.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIPO Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docx_pathZ)\n",
    "print(docx_path1Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSONTipoZ(docx_pathZ):     \n",
    "    texto_LIMPIO = extraer_texto_LIMPIO(docx_pathZ) #SIN NOTE Y TEXT\n",
    "    texto_LIMPIO = texto_LIMPIO.split('\\n')\n",
    "    texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"] \n",
    "    texto_LIMPIO = [elemento.replace(\"\\xa0\", \"\") for elemento in texto_LIMPIO]\n",
    "    texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"]\n",
    "    \n",
    "    a = extraer_texto_en_parrafosTOTAL_SINEXCLUIDAS(docx_pathZ)\n",
    "    a = [elemento for elemento in a if elemento != \"\"] \n",
    "    a = [elemento.replace(\"\\xa0\", \"\") for elemento in a]\n",
    "    a = [elemento for elemento in a if elemento != \"\"] \n",
    "    \n",
    "    b = todo(docx_pathZ)\n",
    "    #com = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "    \n",
    "    #comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "    #comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "    com = extraer_comentarios(docx_pathZ)\n",
    "    #PREPROCESAMIENTO\n",
    "    mi_lista_limpia1 = [elemento.replace(\"\\xa0\", \" \") for elemento in b]\n",
    "    mi_lista_limpia1 = [elemento.replace(\"\\r\\n\", \"\") for elemento in mi_lista_limpia1]\n",
    "    mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \"\"]\n",
    "    mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \" \"]\n",
    "    mi_lista_limpia1 = mi_lista_limpia1[1:-1]\n",
    "    resultado = [elemento for elemento in mi_lista_limpia1 if elemento not in com]\n",
    "    \n",
    "    #print(comentarios_texto)\n",
    "    for i in com:\n",
    "        resultado3 = [elemento.replace(i,\"\") for elemento in resultado]\n",
    "        \n",
    "    un = a[-(len(a)-len(texto_LIMPIO)):]\n",
    "    nota = un[-1]\n",
    "    conclusion = un[:-1]\n",
    "    #print(nota), print(conclusion)\n",
    "    \n",
    "    #NOME\n",
    "    nome = texto_LIMPIO[0].replace(\"Nome: \", \"\").replace(\"Nome:\", \"\").replace(\"Aluno: \", \"\").replace(\"Aluno:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CORREO\n",
    "    correo = texto_LIMPIO[0].replace(\"E-mail: \", \"\").replace(\"E-mail:\", \"\").replace(\"Email: \", \"\").replace(\"Email:\", \"\").replace(\"\\xa0\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CODIGO\n",
    "    codigo = texto_LIMPIO[0].replace(\"Código de identificação: \", \"\").replace(\"Código de identificação:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #NOTA\n",
    "    \n",
    "    #nota = texto_LIMPIO[-1].replace(\"NOTA: \", \"\").replace(\"nota: \", \"\").replace(\"Nota \", \"\")\n",
    "    #del texto_LIMPIO[-1]\n",
    "    comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "    comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "    \n",
    "    t2 = a[:len(texto_LIMPIO)]\n",
    "    t2 = t2[3:]\n",
    "    \n",
    "    resultado1 = resultado[:len(texto_LIMPIO)]\n",
    "    resultado1 = resultado1[3:]\n",
    "    \n",
    "    cuerpo = t2\n",
    "    \n",
    "    # OBTENER PALABRAS COMPLETA CON ERROR\n",
    "    PALABRAS_CON_ERROR = []\n",
    "    for s1, s2 in zip(resultado1, t2):\n",
    "        palabras_s1 = s1.split()\n",
    "        palabras_s2 = s2.split()\n",
    "        palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "        frase_resultante = ' '.join(palabras_restantes)\n",
    "        PALABRAS_CON_ERROR.extend(frase_resultante.split())\n",
    "    \n",
    "    #print(PALABRAS_CON_ERROR) \n",
    "    \n",
    "    # OBTENER PALABRAS LIMPIAS CORREGIDAS\n",
    "    PALABRAS_CORREGIDO = []\n",
    "    for s1, s2 in zip(t2, resultado1):\n",
    "        palabras_s1 = s1.split()\n",
    "        palabras_s2 = s2.split()\n",
    "        palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "        frase_resultante = ' '.join(palabras_restantes)\n",
    "        PALABRAS_CORREGIDO.extend(frase_resultante.split())\n",
    "    \n",
    "    #print(PALABRAS_CORREGIDO) \n",
    "    palabras_corregidas = [PALABRAS_CON_ERROR,PALABRAS_CORREGIDO]\n",
    "    \n",
    "    datos = {\n",
    "        \"NOMBRE\": nome,\n",
    "        \"CORREO\": correo,\n",
    "        \"CODIGO\": codigo,\n",
    "        \"CUERPO\": cuerpo,\n",
    "        \"COMENTARIOS\": comentarios_texto,\n",
    "        \"PALABRAS_CORREGIDAS\":palabras_corregidas,\n",
    "        \"CONCLUSION\": {\n",
    "            \"NOTA\": nota,\n",
    "            \"TEXT\": conclusion\n",
    "        }\n",
    "    }\n",
    "    json_str = json.dumps(datos, ensure_ascii=False, indent=4)\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "comentarios_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = JSONTipoZ(docx_pathZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_filtradosZ1 = archivos_filtradosZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_filtradosZ[0][\"archivo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'AI-Redações/RedaçõesDownloaded/' #modificar el algoritmo si es q no hay comentarios\n",
    "for i in archivos_filtradosZ1:\n",
    "    print(i[\"id\"],i[\"archivo\"])\n",
    "    i[\"JSON\"] = JSONTipoZ(r+str(i[\"id\"])+\"/\"+str(i[\"archivo\"]))\n",
    "    #JSON = JSONTipoA(r+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_filtradosZ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(archivos_filtradosZ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(archivos_filtradosZ[10][\"JSON\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {}\n",
    "Lid,Larchivo,Ltexto,Lcomentario,Lpalabras_corregidas = [],[],[],[],[]\n",
    "tabla = pd.DataFrame()\n",
    "for j in range(len(archivos_filtradosZ)):\n",
    "    data = json.loads(archivos_filtradosZ[j]['JSON'])\n",
    "    #data[\"COMENTARIOS\"]\n",
    "    for i in range(len(data[\"COMENTARIOS\"])):\n",
    "        print(data[\"COMENTARIOS\"][i][1])\n",
    "        #tabla[\"texto\"] = [data[\"COMENTARIOS\"][i][1]]\n",
    "        #texto = data[\"COMENTARIOS\"][i][1]\n",
    "        Lid.append(archivos_filtradosZ[j][\"id\"])\n",
    "        Larchivo.append(archivos_filtradosZ[j]['archivo'])\n",
    "        Ltexto.append(data[\"COMENTARIOS\"][i][1])\n",
    "        Lcomentario.append(data[\"COMENTARIOS\"][i][0])\n",
    "        Lpalabras_corregidas.append(data[\"PALABRAS_CORREGIDAS\"])\n",
    "        #comentario = data[\"COMENTARIOS\"][i][0]\n",
    "        print(data[\"COMENTARIOS\"][i][0])\n",
    "        #diccionario[\"texto\"] = texto\n",
    "        #diccionario[\"comentario\"] = comentario\n",
    "        #tabla[\"comentario\"] = [data[\"COMENTARIOS\"][i][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {\n",
    "    \"id\":Lid,\n",
    "    \"archivo\":Larchivo,\n",
    "    \"texto\": Ltexto,\n",
    "    \"comentario\":Lcomentario,\n",
    "    \"palabras_corregidas\":Lpalabras_corregidas\n",
    "}\n",
    "df = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lpalabras_corregidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"palabras_corregidas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"archivoZ.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIPO R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_pathR = \"AI-Redações/RedaçõesDownloaded/R2/Erick Vinicius R.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_pathR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSONTipoR(docx_pathR):     \n",
    "    texto_LIMPIO = extraer_texto_LIMPIO(docx_pathR) #SIN NOTE Y TEXT\n",
    "    texto_LIMPIO = texto_LIMPIO.split('\\n')\n",
    "    texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"] \n",
    "    texto_LIMPIO = [elemento.replace(\"\\xa0\", \"\") for elemento in texto_LIMPIO]\n",
    "    texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"]\n",
    "    \n",
    "    a = extraer_texto_en_parrafosTOTAL_SINEXCLUIDAS(docx_pathR)\n",
    "    a = [elemento for elemento in a if elemento != \"\"] \n",
    "    a = [elemento.replace(\"\\xa0\", \"\") for elemento in a]\n",
    "    a = [elemento for elemento in a if elemento != \"\"] \n",
    "    \n",
    "    b = todo(docx_pathR)\n",
    "    #com = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "    \n",
    "    #comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "    #comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "    com = extraer_comentarios(docx_pathR)\n",
    "    #PREPROCESAMIENTO\n",
    "    mi_lista_limpia1 = [elemento.replace(\"\\xa0\", \" \") for elemento in b]\n",
    "    mi_lista_limpia1 = [elemento.replace(\"\\r\\n\", \"\") for elemento in mi_lista_limpia1]\n",
    "    mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \"\"]\n",
    "    mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \" \"]\n",
    "    mi_lista_limpia1 = mi_lista_limpia1[1:-1]\n",
    "    resultado = [elemento for elemento in mi_lista_limpia1 if elemento not in com]\n",
    "    \n",
    "    #print(comentarios_texto)\n",
    "    for i in com:\n",
    "        resultado3 = [elemento.replace(i,\"\") for elemento in resultado]\n",
    "        \n",
    "    un = a[-(len(a)-len(texto_LIMPIO)):]\n",
    "    nota = un[-1]\n",
    "    conclusion = un[:-1]\n",
    "    #print(nota), print(conclusion)\n",
    "    \n",
    "    #NOME\n",
    "    nome = texto_LIMPIO[0].replace(\"Nome: \", \"\").replace(\"Nome:\", \"\").replace(\"Aluno: \", \"\").replace(\"Aluno:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CORREO\n",
    "    correo = texto_LIMPIO[0].replace(\"E-mail: \", \"\").replace(\"E-mail:\", \"\").replace(\"Email: \", \"\").replace(\"Email:\", \"\").replace(\"\\xa0\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CODIGO\n",
    "    codigo = texto_LIMPIO[0].replace(\"Código de identificação: \", \"\").replace(\"Código de identificação:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #NOTA\n",
    "    \n",
    "    #nota = texto_LIMPIO[-1].replace(\"NOTA: \", \"\").replace(\"nota: \", \"\").replace(\"Nota \", \"\")\n",
    "    #del texto_LIMPIO[-1]\n",
    "    comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathR)\n",
    "    comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "    \n",
    "    t2 = a[:len(texto_LIMPIO)]\n",
    "    t2 = t2[3:]\n",
    "    \n",
    "    resultado1 = resultado[:len(texto_LIMPIO)]\n",
    "    resultado1 = resultado1[3:]\n",
    "    \n",
    "    cuerpo = t2\n",
    "    \n",
    "    # OBTENER PALABRAS COMPLETA CON ERROR\n",
    "    PALABRAS_CON_ERROR = []\n",
    "    for s1, s2 in zip(resultado1, t2):\n",
    "        palabras_s1 = s1.split()\n",
    "        palabras_s2 = s2.split()\n",
    "        palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "        frase_resultante = ' '.join(palabras_restantes)\n",
    "        PALABRAS_CON_ERROR.extend(frase_resultante.split())\n",
    "    \n",
    "    #print(PALABRAS_CON_ERROR) \n",
    "    \n",
    "    # OBTENER PALABRAS LIMPIAS CORREGIDAS\n",
    "    PALABRAS_CORREGIDO = []\n",
    "    for s1, s2 in zip(t2, resultado1):\n",
    "        palabras_s1 = s1.split()\n",
    "        palabras_s2 = s2.split()\n",
    "        palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "        frase_resultante = ' '.join(palabras_restantes)\n",
    "        PALABRAS_CORREGIDO.extend(frase_resultante.split())\n",
    "    \n",
    "    #print(PALABRAS_CORREGIDO) \n",
    "    palabras_corregidas = [PALABRAS_CON_ERROR,PALABRAS_CORREGIDO]\n",
    "    \n",
    "    datos = {\n",
    "        \"NOMBRE\": nome,\n",
    "        \"CORREO\": correo,\n",
    "        \"CODIGO\": codigo,\n",
    "        \"CUERPO\": cuerpo,\n",
    "        \"COMENTARIOS\": comentarios_texto,\n",
    "        \"PALABRAS_CORREGIDAS\":palabras_corregidas,\n",
    "        \"CONCLUSION\": {\n",
    "            \"NOTA\": nota,\n",
    "            \"TEXT\": conclusion\n",
    "        }\n",
    "    }\n",
    "    json_str = json.dumps(datos, ensure_ascii=False, indent=4)\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = JSONTipoR(docx_pathR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIPO R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_filtradosR[0][\"archivo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_filtradosR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_pathR = 'AI-Redações/RedaçõesDownloaded/R12/'+archivos_filtradosR[0][\"archivo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSONTipoR(docx_pathR):     \n",
    "    texto_LIMPIO = extraer_texto_LIMPIO(docx_pathR) #SIN NOTE Y TEXT\n",
    "    texto_LIMPIO = texto_LIMPIO.split('\\n')\n",
    "    texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"] \n",
    "    texto_LIMPIO = [elemento.replace(\"\\xa0\", \"\") for elemento in texto_LIMPIO]\n",
    "    texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"]\n",
    "    \n",
    "    a = extraer_texto_en_parrafosTOTAL_SINEXCLUIDAS(docx_pathR)\n",
    "    a = [elemento for elemento in a if elemento != \"\"] \n",
    "    a = [elemento.replace(\"\\xa0\", \"\") for elemento in a]\n",
    "    a = [elemento for elemento in a if elemento != \"\"] \n",
    "    \n",
    "    b = todo(docx_pathR)\n",
    "    #com = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "    \n",
    "    #comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "    #comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "    com = extraer_comentarios(docx_pathR)\n",
    "    #PREPROCESAMIENTO\n",
    "    mi_lista_limpia1 = [elemento.replace(\"\\xa0\", \" \") for elemento in b]\n",
    "    mi_lista_limpia1 = [elemento.replace(\"\\r\\n\", \"\") for elemento in mi_lista_limpia1]\n",
    "    mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \"\"]\n",
    "    mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \" \"]\n",
    "    mi_lista_limpia1 = mi_lista_limpia1[1:-1]\n",
    "    resultado = [elemento for elemento in mi_lista_limpia1 if elemento not in com]\n",
    "    \n",
    "    #print(comentarios_texto)\n",
    "    for i in com:\n",
    "        resultado3 = [elemento.replace(i,\"\") for elemento in resultado]\n",
    "        \n",
    "    un = a[-(len(a)-len(texto_LIMPIO)):]\n",
    "    nota = un[-1]\n",
    "    conclusion = un[:-1]\n",
    "    #print(nota), print(conclusion)\n",
    "    \n",
    "    #NOME\n",
    "    nome = texto_LIMPIO[0].replace(\"Nome: \", \"\").replace(\"Nome:\", \"\").replace(\"Aluno: \", \"\").replace(\"Aluno:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CORREO\n",
    "    correo = texto_LIMPIO[0].replace(\"E-mail: \", \"\").replace(\"E-mail:\", \"\").replace(\"Email: \", \"\").replace(\"Email:\", \"\").replace(\"\\xa0\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #CODIGO\n",
    "    codigo = texto_LIMPIO[0].replace(\"Código de identificação: \", \"\").replace(\"Código de identificação:\", \"\")\n",
    "    del texto_LIMPIO[0]\n",
    "    #NOTA\n",
    "    \n",
    "    #nota = texto_LIMPIO[-1].replace(\"NOTA: \", \"\").replace(\"nota: \", \"\").replace(\"Nota \", \"\")\n",
    "    #del texto_LIMPIO[-1]\n",
    "    comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathR)\n",
    "    comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    "    \n",
    "    t2 = a[:len(texto_LIMPIO)]\n",
    "    t2 = t2[3:]\n",
    "    \n",
    "    resultado1 = resultado[:len(texto_LIMPIO)]\n",
    "    resultado1 = resultado1[3:]\n",
    "    \n",
    "    cuerpo = t2\n",
    "    \n",
    "    # OBTENER PALABRAS COMPLETA CON ERROR\n",
    "    PALABRAS_CON_ERROR = []\n",
    "    for s1, s2 in zip(resultado1, t2):\n",
    "        palabras_s1 = s1.split()\n",
    "        palabras_s2 = s2.split()\n",
    "        palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "        frase_resultante = ' '.join(palabras_restantes)\n",
    "        PALABRAS_CON_ERROR.extend(frase_resultante.split())\n",
    "    \n",
    "    #print(PALABRAS_CON_ERROR) \n",
    "    \n",
    "    # OBTENER PALABRAS LIMPIAS CORREGIDAS\n",
    "    PALABRAS_CORREGIDO = []\n",
    "    for s1, s2 in zip(t2, resultado1):\n",
    "        palabras_s1 = s1.split()\n",
    "        palabras_s2 = s2.split()\n",
    "        palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "        frase_resultante = ' '.join(palabras_restantes)\n",
    "        PALABRAS_CORREGIDO.extend(frase_resultante.split())\n",
    "    \n",
    "    #print(PALABRAS_CORREGIDO) \n",
    "    palabras_corregidas = [PALABRAS_CON_ERROR,PALABRAS_CORREGIDO]\n",
    "    \n",
    "    datos = {\n",
    "        \"NOMBRE\": nome,\n",
    "        \"CORREO\": correo,\n",
    "        \"CODIGO\": codigo,\n",
    "        \"CUERPO\": cuerpo,\n",
    "        \"COMENTARIOS\": comentarios_texto,\n",
    "        \"PALABRAS_CORREGIDAS\":palabras_corregidas,\n",
    "        \"CONCLUSION\": {\n",
    "            \"NOTA\": nota,\n",
    "            \"TEXT\": conclusion\n",
    "        }\n",
    "    }\n",
    "    json_str = json.dumps(datos, ensure_ascii=False, indent=4)\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_pathR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = JSONTipoR(docx_pathR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'AI-Redações/RedaçõesDownloaded/' #modificar el algoritmo si es q no hay comentarios\n",
    "for i in archivos_filtradosR:\n",
    "    print(i[\"id\"],i[\"archivo\"])\n",
    "    i[\"JSON\"] = JSONTipoR(r+str(i[\"id\"])+\"/\"+str(i[\"archivo\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {}\n",
    "Lid,Larchivo,Ltexto,Lcomentario,Lpalabras_corregidas = [],[],[],[],[]\n",
    "tabla = pd.DataFrame()\n",
    "for j in range(len(archivos_filtradosR)):\n",
    "    data = json.loads(archivos_filtradosR[j]['JSON'])\n",
    "    #data[\"COMENTARIOS\"]\n",
    "    for i in range(len(data[\"COMENTARIOS\"])):\n",
    "        print(data[\"COMENTARIOS\"][i][1])\n",
    "        #tabla[\"texto\"] = [data[\"COMENTARIOS\"][i][1]]\n",
    "        #texto = data[\"COMENTARIOS\"][i][1]\n",
    "        Lid.append(archivos_filtradosR[j][\"id\"])\n",
    "        Larchivo.append(archivos_filtradosR[j]['archivo'])\n",
    "        Ltexto.append(data[\"COMENTARIOS\"][i][1])\n",
    "        Lcomentario.append(data[\"COMENTARIOS\"][i][0])\n",
    "        Lpalabras_corregidas.append(data[\"PALABRAS_CORREGIDAS\"])\n",
    "        #comentario = data[\"COMENTARIOS\"][i][0]\n",
    "        print(data[\"COMENTARIOS\"][i][0])\n",
    "        #diccionario[\"texto\"] = texto\n",
    "        #diccionario[\"comentario\"] = comentario\n",
    "        #tabla[\"comentario\"] = [data[\"COMENTARIOS\"][i][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {\n",
    "    \"id\":Lid,\n",
    "    \"archivo\":Larchivo,\n",
    "    \"texto\": Ltexto,\n",
    "    \"comentario\":Lcomentario,\n",
    "    \"palabras_corregidas\":Lpalabras_corregidas\n",
    "}\n",
    "df = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {\n",
    "    \"id\":Lid,\n",
    "    \"archivo\":Larchivo,\n",
    "    \"texto\": Ltexto,\n",
    "    \"comentario\":Lcomentario,\n",
    "    \"palabras_corregidas\":Lpalabras_corregidas\n",
    "}\n",
    "df = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df[\"palabras_corregidas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"archivoR.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRECION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_pathZ = 'AI-Redações/RedaçõesDownloaded/R1/DIOGO DAVID SÁNCHEZ LIMA Z.docx'\n",
    "docx_path1Z = 'AI-Redações/RedaçõesDownloaded/R1/Davi Natael da Cunha  ZZ.docx'\n",
    "docx_path2Z = 'AI-Redações/RedaçõesDownloaded/R1/Carallow ZZ.docx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI-Redações/RedaçõesDownloaded/R1/DIOGO DAVID SÁNCHEZ LIMA Z.docx'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_pathZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_LIMPIO = extraer_texto_LIMPIO(docx_pathZ) #SIN NOTE Y TEXT\n",
    "texto_LIMPIO = texto_LIMPIO.split('\\n')\n",
    "texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"] \n",
    "texto_LIMPIO = [elemento.replace(\"\\xa0\", \"\") for elemento in texto_LIMPIO]\n",
    "texto_LIMPIO = [elemento for elemento in texto_LIMPIO if elemento != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = extraer_texto_en_parrafosTOTAL_SINEXCLUIDAS(docx_pathZ)\n",
    "a = [elemento for elemento in a if elemento != \"\"] \n",
    "a = [elemento.replace(\"\\xa0\", \"\") for elemento in a]\n",
    "a = [elemento for elemento in a if elemento != \"\"] \n",
    "\n",
    "b = todo(docx_pathZ)\n",
    "#com = obtener_comentari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIOGO DAVID SÁNCHEZ LIMA',\n",
       " 'dgsp3000ac@gmail.com',\n",
       " 'R1N022',\n",
       " 'THC: TRANSTORNO DO HOMEM PELO CELULAR',\n",
       " ' Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias esmartphonese a maneira como esse vício tornou-se prejudicial à sociedade .',\n",
       " ' Segundo O Globo, o número de pessoas com problemas na coluna cervical aumentou em até 40%, sendo que a maioria desses casos envolve jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.',\n",
       " ' Outro mal dessas tecnologias é que o uso desses dispositivos não agride só a saúde do usuário como também põe em risco a vida de terceiros. De acordo com a Abramet, são cerca de 54.000 mortes por ano no Brasil devido à utilização desses aparelhos no trânsito.',\n",
       " ' O grande responsável por todos esses problemas, não é única e exclusivamente o celular; o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.',\n",
       " ' São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde está concentrada a maior parte dos usuários desses dispositivos móveis, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.',\n",
       " 'Falta muita leitura e informação.',\n",
       " 'Pouca prática redacional e erros gramaticais para todos os gostos.',\n",
       " 'Precisa melhorar bastante.',\n",
       " 'Nota 3,0']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Evaluation Only. Created with Aspose.Words. Copyright 2003-2023 Aspose Pty Ltd.\\r\\n',\n",
       " 'DIOGO DAVID SÁNCHEZ LIMA\\r\\n',\n",
       " 'dgsp3000ac@gmail.com\\r\\n',\n",
       " 'R1N022\\r\\n',\n",
       " '\\xa0\\r\\n',\n",
       " 'THC: TRANSTORNO DO HOMEM PELO CELULAR\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias e\\xa0smartphones\\xa0e a maneira comocom que esse vício tornou-seé prejudicial àna sociedade atual\\r\\nBom início.\\r\\n.\\r\\n',\n",
       " 'Bom início.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Segundo O Globo, o número de pessoas com problemas na coluna cervical aumentouaram em até 40%, sendo que a maioria desses casos envolvem jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Outro malu dessas tecnologias é que, o uso desses dispositivos não agridem\\r\\nVocê erra o tempo inteiro na concordância.\\r\\n só a saúde do usuário como também põem em risco a vida de terceiros. De, de acordo com a Aabramet, são cerca de 54.000 mortes por ano no Brasil devido àa utilização desses aparelhos no trânsito.\\r\\n',\n",
       " 'Você erra o tempo inteiro na concordância.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.\\r\\nClaro que o aparelho não tem culpa e sim quem o utiliza.\\r\\n\\r\\n',\n",
       " 'Claro que o aparelho não tem culpa e sim quem o utiliza.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveis\\r\\nNão é bem verdade o que você diz\\r\\n, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.\\r\\n',\n",
       " 'Não é bem verdade o que você diz\\r\\n',\n",
       " 'Falta muita leitura e informação.\\r\\n',\n",
       " 'Pouca prática redacional e erros gramaticais para todos os gostos.\\r\\n',\n",
       " 'Precisa melhorar bastante.\\r\\n',\n",
       " 'Nota 3,0\\r\\n',\n",
       " '\\r\\n',\n",
       " 'Created with an evaluation copy of Aspose.Words. To discover the full versions of our APIs please visit: https://products.aspose.com/words/\\r\\n',\n",
       " '\\r\\n']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = extraer_comentarios(docx_pathZ)\n",
    "#PREPROCESAMIENTO\n",
    "mi_lista_limpia1 = [elemento.replace(\"\\xa0\", \" \") for elemento in b]\n",
    "mi_lista_limpia1 = [elemento.replace(\"\\r\\n\", \"\") for elemento in mi_lista_limpia1]\n",
    "mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \"\"]\n",
    "mi_lista_limpia1 = [elemento for elemento in mi_lista_limpia1 if elemento != \" \"]\n",
    "mi_lista_limpia1 = mi_lista_limpia1[1:-1]\n",
    "resultado = [elemento for elemento in mi_lista_limpia1 if elemento not in com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#com = extraer_comentarios(docx_pathZ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIOGO DAVID SÁNCHEZ LIMA',\n",
       " 'dgsp3000ac@gmail.com',\n",
       " 'R1N022',\n",
       " 'THC: TRANSTORNO DO HOMEM PELO CELULAR',\n",
       " '          Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias e smartphones e a maneira comocom que esse vício tornou-seé prejudicial àna sociedade atualBom início..',\n",
       " '          Segundo O Globo, o número de pessoas com problemas na coluna cervical aumentouaram em até 40%, sendo que a maioria desses casos envolvem jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.',\n",
       " '          Outro malu dessas tecnologias é que, o uso desses dispositivos não agridemVocê erra o tempo inteiro na concordância. só a saúde do usuário como também põem em risco a vida de terceiros. De, de acordo com a Aabramet, são cerca de 54.000 mortes por ano no Brasil devido àa utilização desses aparelhos no trânsito.',\n",
       " '          O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       " '          São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveisNão é bem verdade o que você diz, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.',\n",
       " 'Falta muita leitura e informação.',\n",
       " 'Pouca prática redacional e erros gramaticais para todos os gostos.',\n",
       " 'Precisa melhorar bastante.',\n",
       " 'Nota 3,0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in com:\n",
    "    resultado3 = [elemento.replace(i,\"\") for elemento in resultado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIOGO DAVID SÁNCHEZ LIMA',\n",
       " 'dgsp3000ac@gmail.com',\n",
       " 'R1N022',\n",
       " 'THC: TRANSTORNO DO HOMEM PELO CELULAR',\n",
       " '          Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias e smartphones e a maneira comocom que esse vício tornou-seé prejudicial àna sociedade atualBom início..',\n",
       " '          Segundo O Globo, o número de pessoas com problemas na coluna cervical aumentouaram em até 40%, sendo que a maioria desses casos envolvem jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.',\n",
       " '          Outro malu dessas tecnologias é que, o uso desses dispositivos não agridemVocê erra o tempo inteiro na concordância. só a saúde do usuário como também põem em risco a vida de terceiros. De, de acordo com a Aabramet, são cerca de 54.000 mortes por ano no Brasil devido àa utilização desses aparelhos no trânsito.',\n",
       " '          O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       " '          São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveis, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.',\n",
       " 'Falta muita leitura e informação.',\n",
       " 'Pouca prática redacional e erros gramaticais para todos os gostos.',\n",
       " 'Precisa melhorar bastante.',\n",
       " 'Nota 3,0']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = a[-(len(a)-len(texto_LIMPIO)):]\n",
    "nota = un[-1]\n",
    "conclusion = un[:-1]\n",
    "#print(nota), print(conclusion)\n",
    "\n",
    "#NOME\n",
    "nome = texto_LIMPIO[0].replace(\"Nome: \", \"\").replace(\"Nome:\", \"\").replace(\"Aluno: \", \"\").replace(\"Aluno:\", \"\")\n",
    "del texto_LIMPIO[0]\n",
    "#CORREO\n",
    "correo = texto_LIMPIO[0].replace(\"E-mail: \", \"\").replace(\"E-mail:\", \"\").replace(\"Email: \", \"\").replace(\"Email:\", \"\").replace(\"\\xa0\", \"\")\n",
    "del texto_LIMPIO[0]\n",
    "#CODIGO\n",
    "codigo = texto_LIMPIO[0].replace(\"Código de identificação: \", \"\").replace(\"Código de identificação:\", \"\")\n",
    "del texto_LIMPIO[0]\n",
    "#NOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " #nota = texto_LIMPIO[-1].replace(\"NOTA: \", \"\").replace(\"nota: \", \"\").replace(\"Nota \", \"\")\n",
    " #del texto_LIMPIO[-1]\n",
    "comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathZ)\n",
    "comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]\n",
    " \n",
    "t2 = a[:len(texto_LIMPIO)]\n",
    "t2 = t2[3:]\n",
    " \n",
    "resultado1 = resultado[:len(texto_LIMPIO)]\n",
    "resultado1 = resultado1[3:]\n",
    " \n",
    "cuerpo = t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTENER PALABRAS COMPLETA CON ERROR\n",
    "PALABRAS_CON_ERROR = []\n",
    "for s1, s2 in zip(resultado1, t2):\n",
    "    palabras_s1 = s1.split()\n",
    "    palabras_s2 = s2.split()\n",
    "    palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "    frase_resultante = ' '.join(palabras_restantes)\n",
    "    PALABRAS_CON_ERROR.extend(frase_resultante.split())\n",
    "\n",
    "#print(PALABRAS_CON_ERROR) \n",
    "\n",
    "# OBTENER PALABRAS LIMPIAS CORREGIDAS\n",
    "PALABRAS_CORREGIDO = []\n",
    "for s1, s2 in zip(t2, resultado1):\n",
    "    palabras_s1 = s1.split()\n",
    "    palabras_s2 = s2.split()\n",
    "    palabras_restantes = [palabra for palabra in palabras_s1 if palabra not in palabras_s2]\n",
    "    frase_resultante = ' '.join(palabras_restantes)\n",
    "    PALABRAS_CORREGIDO.extend(frase_resultante.split())\n",
    "\n",
    "#print(PALABRAS_CORREGIDO) \n",
    "palabras_corregidas = [PALABRAS_CON_ERROR,PALABRAS_CORREGIDO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smartphones',\n",
       " 'comocom',\n",
       " 'tornou-seé',\n",
       " 'àna',\n",
       " 'atualBom',\n",
       " 'início..',\n",
       " 'aumentouaram',\n",
       " 'envolvem']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PALABRAS_CON_ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esmartphonese', 'como', 'tornou-se', 'à', '.', 'aumentou', 'envolve']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PALABRAS_CORREGIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios_y_texto = obtener_comentarios_y_texto_asociado(docx_pathZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\x05Bom início.', 'atual'),\n",
       " ('\\x05Você erra o tempo inteiro na concordância.', 'agridem'),\n",
       " ('\\x05Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       "  'O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.'),\n",
       " ('\\x05Não é bem verdade o que você diz',\n",
       "  'nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveis')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios_y_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios_texto = [(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bom início.', 'atual'),\n",
       " ('Você erra o tempo inteiro na concordância.', 'agridem'),\n",
       " ('Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       "  'O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.'),\n",
       " ('Não é bem verdade o que você diz',\n",
       "  'nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveis')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(tupla[0].replace('\\x05', ''), tupla[1]) for tupla in comentarios_y_texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bom início.', 'atual'),\n",
       " ('Você erra o tempo inteiro na concordância.', 'agridem'),\n",
       " ('Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       "  'O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.'),\n",
       " ('Não é bem verdade o que você diz',\n",
       "  'nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveis')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom início.\n",
      "Você erra o tempo inteiro na concordância.\n",
      "Claro que o aparelho não tem culpa e sim quem o utiliza.\n",
      "Não é bem verdade o que você diz\n"
     ]
    }
   ],
   "source": [
    "coment = []\n",
    "for i in comentarios_texto:\n",
    "    print(i[0])\n",
    "    coment.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bom início.',\n",
       " 'Você erra o tempo inteiro na concordância.',\n",
       " 'Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       " 'Não é bem verdade o que você diz']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIOGO DAVID SÁNCHEZ LIMA',\n",
       " 'dgsp3000ac@gmail.com',\n",
       " 'R1N022',\n",
       " 'THC: TRANSTORNO DO HOMEM PELO CELULAR',\n",
       " '          Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias e smartphones e a maneira comocom que esse vício tornou-seé prejudicial àna sociedade atualBom início..',\n",
       " 'Bom início.',\n",
       " '          Segundo O Globo, o número de pessoas com problemas na coluna cervical aumentouaram em até 40%, sendo que a maioria desses casos envolvem jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.',\n",
       " '          Outro malu dessas tecnologias é que, o uso desses dispositivos não agridemVocê erra o tempo inteiro na concordância. só a saúde do usuário como também põem em risco a vida de terceiros. De, de acordo com a Aabramet, são cerca de 54.000 mortes por ano no Brasil devido àa utilização desses aparelhos no trânsito.',\n",
       " 'Você erra o tempo inteiro na concordância.',\n",
       " '          O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       " 'Claro que o aparelho não tem culpa e sim quem o utiliza.',\n",
       " '          São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveisNão é bem verdade o que você diz, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.',\n",
       " 'Não é bem verdade o que você diz',\n",
       " 'Falta muita leitura e informação.',\n",
       " 'Pouca prática redacional e erros gramaticais para todos os gostos.',\n",
       " 'Precisa melhorar bastante.',\n",
       " 'Nota 3,0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_lista_limpia1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docx_pathZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def extraer_palabras_tachadas(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "\n",
    "    palabras_tachadas = []\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.strike:\n",
    "                palabras_tachadas.append(run.text)\n",
    "\n",
    "    return palabras_tachadas\n",
    "\n",
    "# Ruta de tu documento Word docx_pathZ\n",
    "ruta_documento = docx_pathZ\n",
    "\n",
    "# Llamada a la función\n",
    "palabras_tachadas = extraer_palabras_tachadas(ruta_documento)\n",
    "\n",
    "# Imprimir las palabras tachadas\n",
    "for palabra in palabras_tachadas:\n",
    "    print(palabra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_tachadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI-Redações/RedaçõesDownloaded/R1/DIOGO DAVID SÁNCHEZ LIMA Z.docx'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_pathZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3963 sha256=145ea8e6c52df2844abe5db8b514c5d151d5befc4a3c18ad68896d49e4376de5\n",
      "  Stored in directory: /home/andres/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras tachadas:\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "\n",
    "def extraer_palabras_tachadas(docx_path):\n",
    "    document = Document(docx_path)\n",
    "\n",
    "    palabras_tachadas = []\n",
    "\n",
    "    for paragraph in document.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            # Verificar si la fuente tiene el atributo strike y size menor a 1\n",
    "            if run.font.strike and run.font.size < Pt(20):\n",
    "                palabras_tachadas.append(run.text)\n",
    "\n",
    "    return palabras_tachadas\n",
    "\n",
    "# Ruta al archivo Word\n",
    "archivo_word = docx_pathZ\n",
    "\n",
    "# Llamada a la función para extraer palabras tachadas\n",
    "palabras_tachadas = extraer_palabras_tachadas(docx_pathZ)\n",
    "\n",
    "# Imprimir las palabras tachadas\n",
    "print(\"Palabras tachadas:\")\n",
    "for palabra in palabras_tachadas:\n",
    "    print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI-Redações/RedaçõesDownloaded/R1/DIOGO DAVID SÁNCHEZ LIMA Z.docx'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_pathZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Evaluation Only. Created with Aspose.Words. Copyright 2003-2023 Aspose Pty Ltd.\\r\\n',\n",
       " 'DIOGO DAVID SÁNCHEZ LIMA\\r\\n',\n",
       " 'dgsp3000ac@gmail.com\\r\\n',\n",
       " 'R1N022\\r\\n',\n",
       " '\\xa0\\r\\n',\n",
       " 'THC: TRANSTORNO DO HOMEM PELO CELULAR\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias e\\xa0smartphones\\xa0e a maneira comocom que esse vício tornou-seé prejudicial àna sociedade atual\\r\\nBom início.\\r\\n.\\r\\n',\n",
       " 'Bom início.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Segundo O Globo, o número de pessoas com problemas na coluna cervical aumentouaram em até 40%, sendo que a maioria desses casos envolvem jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Outro malu dessas tecnologias é que, o uso desses dispositivos não agridem\\r\\nVocê erra o tempo inteiro na concordância.\\r\\n só a saúde do usuário como também põem em risco a vida de terceiros. De, de acordo com a Aabramet, são cerca de 54.000 mortes por ano no Brasil devido àa utilização desses aparelhos no trânsito.\\r\\n',\n",
       " 'Você erra o tempo inteiro na concordância.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 O grande responsável por todas essestodos esses problemas, não é única e exclusivamente o celular;, o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.\\r\\nClaro que o aparelho não tem culpa e sim quem o utiliza.\\r\\n\\r\\n',\n",
       " 'Claro que o aparelho não tem culpa e sim quem o utiliza.\\r\\n',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde estáa concentrada a maior parte dos usuários desses dispositivos móveis\\r\\nNão é bem verdade o que você diz\\r\\n, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.\\r\\n',\n",
       " 'Não é bem verdade o que você diz\\r\\n',\n",
       " 'Falta muita leitura e informação.\\r\\n',\n",
       " 'Pouca prática redacional e erros gramaticais para todos os gostos.\\r\\n',\n",
       " 'Precisa melhorar bastante.\\r\\n',\n",
       " 'Nota 3,0\\r\\n',\n",
       " '\\r\\n',\n",
       " 'Created with an evaluation copy of Aspose.Words. To discover the full versions of our APIs please visit: https://products.aspose.com/words/\\r\\n',\n",
       " '\\r\\n']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo(docx_pathZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIOGO DAVID SÁNCHEZ LIMA\\ndgsp3000ac@gmail.com\\nR1N022\\n\\xa0\\nTHC: TRANSTORNO DO HOMEM PELO CELULAR\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias e\\xa0smartphones\\xa0e a maneira  esse vício  prejudicial  sociedade .\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Segundo O Globo, o número de pessoas com problemas na coluna cervical aument em até 40% sendo que a maioria desses casos envolve jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Outro ma dessas tecnologias é que o uso desses dispositivos não agride só a saúde do usuário como também põe em risco a vida de terceiros acordo com a bramet são cerca de 54.000 mortes por ano no Brasil devido  utilização desses aparelhos no trânsito.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 O grande responsável por  problemas, não é única e exclusivamente o celular o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde est concentrada a maior parte dos usuários desses dispositivos móveis, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraer_texto_LIMPIO(docx_pathZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIOGO DAVID SÁNCHEZ LIMA',\n",
       " 'dgsp3000ac@gmail.com',\n",
       " 'R1N022',\n",
       " '\\xa0',\n",
       " 'THC: TRANSTORNO DO HOMEM PELO CELULAR',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Dependência, palavra que costumava ser usada em diálogos sobre drogas e jogos de azar, hoje pode também ser utilizada quando se trata sobre as novas tecnologias e\\xa0smartphones\\xa0e a maneira como esse vício tornou-se prejudicial à sociedade .',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Segundo O Globo, o número de pessoas com problemas na coluna cervical aumentou em até 40%, sendo que a maioria desses casos envolve jovens que possuem problemas de postura por usar constantemente os celulares de maneira incorreta.',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Outro mal dessas tecnologias é que o uso desses dispositivos não agride só a saúde do usuário como também põe em risco a vida de terceiros. De acordo com a Abramet, são cerca de 54.000 mortes por ano no Brasil devido à utilização desses aparelhos no trânsito.',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 O grande responsável por todos esses problemas, não é única e exclusivamente o celular; o usuário do aparelho também carrega grande parte da culpa, pois se esse utilizasse de maneira adequada o dispositivo, não traria nenhum risco.',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 São necessárias políticas públicas de conscientização, principalmente nas escolas e nas universidades, onde está concentrada a maior parte dos usuários desses dispositivos móveis, para que o crescente número de acidentes e problemas de saúde provocados por este seja remediado e a população possa viver sem esse grave problema.',\n",
       " 'Falta muita leitura e informação.',\n",
       " 'Pouca prática redacional e erros gramaticais para todos os gostos.',\n",
       " 'Precisa melhorar bastante.',\n",
       " 'Nota 3,0',\n",
       " '']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraer_texto_en_parrafosTOTAL_SINEXCLUIDAS(docx_pathZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                   0  1\n",
       " 0  a stirring , funny and finally transporting re...  1\n",
       " 1  apparently reassembled from the cutting room f...  0\n",
       " 2  they presume their audience wo n't sit still f...  0\n",
       " 3  this is a visually stunning rumination on love...  1\n",
       " 4  jonathan parker 's bartleby should have been t...  1,\n",
       " (6920, 2))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2598998052c498ab6a2b3fa2afc36aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading vocab.txt', max=871891.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d28d179bd9d45469b5ea98b3e8b3908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)cial_tokens_map.json', max=112.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e682530bed44affa1d8a3fdcdb07f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading tokenizer_config.json', max=39.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d782ac79072f4b099ea6c1f686c12d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading config.json', max=953.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3765a9f52a36409da96547bc026b27ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading pytorch_model.bin', max=669491321.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentimiento resultante: 4\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar el tokenizador y el modelo preentrenado para análisis de sentimiento\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Crear una función para realizar el análisis de sentimiento\n",
    "def analisis_sentimiento(texto):\n",
    "    tokens = tokenizer(texto, return_tensors='pt')\n",
    "    resultado = model(**tokens)\n",
    "    probabilidad = resultado.logits.softmax(dim=1)\n",
    "    sentimiento = probabilidad.argmax().item()\n",
    "    return sentimiento\n",
    "\n",
    "# Ejemplo de uso\n",
    "texto_ejemplo = \"Estoy muy contento de poder utilizar BERT para análisis de sentimiento.\"\n",
    "sentimiento_resultante = analisis_sentimiento(texto_ejemplo)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"Sentimiento resultante: {sentimiento_resultante}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentimiento2'] = df['Texto'].apply(analisis_sentimiento)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
